# movieLens-embeddings
В этой работе я исследую датасет movieLens и использую BERT для нахождения эмбеддингов пользователей.

# Ответы на важные вопросы

## 1. Разбиение данных на обучение и валидацию
Разбиваю множество `id юзеров` на части train и valid в соотношении `0.7/0.3`.
Я использую `юзеров` для разбиения потому, что создаю эмбеддинги для них, а не для фильмов.
Для фильмов же используются вектора полученные из `genome-scores`.
## 2. Выбор и обоснование метрики
В качестве метрики я использую `косинусное расстояние`, а именно реализацию этой метрики в `sklearn`.
Вектора похожих фильмов могут быть далеко друг от друга по MSE, но быть направлены в одну сторону. 
Например, если векторы разные по длине, но направлены в одну сторону, то MSE выдаст большое значение.
Нам же важна именно сонаправленность векторов. Интуиция здесь такая, что если пользователи A и B любят "Историю игрушек", то мы хотим советовать похожие фильмы им обоим, не смотря на то, что B любит этот фильм сильнее (Вектор B больше по модулю).
## 3. Архитектура нейронной сети
Создаю кастомную архитектуру на основе BERT потому, что BERT наиболее популярная модель, основанная на трансформере. 
BERT показывает хорошие результаты во многих задачах ML, в частности в RecSys.
За основу беру `bert-base-cased` из `huggingface` для задачи классификации на 64 класса, где 64 это размерность эмбеддигов. Беру из него нужны слои и создаю свой класс `BertForUsers(nn.Module)`. Я делаю это для того, что подавать на вход модели то, что мне нужно, а не input_ids, как принято у моделей из `huggingface`.
## 4. Обучение и валидация
У юзера есть видео, которые он оценивал или к которым писал комментарий. Пусть `X` - множество векторов этих видео. Разделим `X` на `X_train` и `next_vector`, где `next_vector` это один вектор. При чем, в качестве `next_vector` возьмем вектор фильма, которому юзер дал наивысшую оценку. Таким образом `next_vector` это самый подходящий фильм для юзера и мы будем стараться сделать вектор для юзера как можно более похожим на `next_vector`.

На вход модель подаются векторы из `X_train` и модель учится предсказывать вектор `next_vector`. В качестве лосса используется `torch.nn.CosineEmbeddingLoss()`.

Предсказанный вектор `next_vector_prediction` будем считать вектором юзера.

Из`genome-scores` получим вектора для видео и положим их в `relevance_matrix`. Будем подавать эти вектора на вход модели `BertForUsers(nn.Module)`, а на выходе получать вектор размерности 64, по которому считаем лосс с `next_vector`, который тоже находится в `relevance_matrix`.

Однако заместо обычных векторов из `relevance_matrix`, будем использовать 3 типа фичей:
- `ranking`, который юзер дал текущему видео
- `movie genre`
- вектор из `relevance_matrix`

Таким образом, если юзер низко оценил видео, то оно почти не будет участвовать в предсказании следующего видео. Также мы учитываем какой жанр был у видео, ведь если юзер плохо оценил определенные жанры, то фильмы такого жанра почти не должны влиять на предсказание следующего видео.

- `ranking` - множитель для вектора
- `movie genre` - вектор размерности 20, полученный из жанров как из категориальных фичей.

Указанные 3 типа фичей соединим с помощью конкатенации и уменьшением размерности.
## 5. Воспроизводимость
- Данный ноутбук был сделан на `kaggle`, так как `colab` зависает при работе с большими ноутбуками.
- Необходимые сохраненные результаты можно найти в соответствующих датасетах на `kaggle`. По ссылкам: [data-for-collate-fn](https://www.kaggle.com/datasets/yaskevichmisha/data-for-collate-fn), [datadet-path](https://www.kaggle.com/datasets/yaskevichmisha/dataset-path)
- В разделе **Data preparation** будет выполняться left join для больших таблиц, что требует **~17GB RAM**. Если RAM не хватает, то нужно пропустить этот шаг и перейти к шагу **Make datasets for Trainer**, где скачиваются необходимые для обучения результаты.

